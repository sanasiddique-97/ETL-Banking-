{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e18baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input consolidated DTRDTR Consolidated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ec1d1ab4da62>:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  cash_late[\"tr_time\"] = cash_late[\"tr_time\"].astype('datetime64[ns]')\n",
      "<ipython-input-1-ec1d1ab4da62>:36: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  w_late[\"tr_time\"] = w_late[\"tr_time\"].astype('datetime64[ns]')\n",
      "<ipython-input-1-ec1d1ab4da62>:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  inw[\"tr_time\"] =inw[\"tr_time\"].astype('datetime64[ns]')\n",
      "<ipython-input-1-ec1d1ab4da62>:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inw[\"tr_time\"] =inw[\"tr_time\"].astype('datetime64[ns]')\n",
      "<ipython-input-1-ec1d1ab4da62>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inw['time']= inw[\"tr_time\"].dt.time\n",
      "<ipython-input-1-ec1d1ab4da62>:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[\"sum\"]= data2.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
      "<ipython-input-1-ec1d1ab4da62>:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[\"sum\"]= data2.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
      "<ipython-input-1-ec1d1ab4da62>:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[\"sum\"] =data2[\"sum\"].abs()\n",
      "<ipython-input-1-ec1d1ab4da62>:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2cw[\"sum\"]= data2cw.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
      "<ipython-input-1-ec1d1ab4da62>:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2cw[\"sum\"] =data2cw[\"sum\"].abs()\n",
      "<ipython-input-1-ec1d1ab4da62>:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2cw[\"sum\"]= data2cw.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
      "<ipython-input-1-ec1d1ab4da62>:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2cw[\"sum\"] =data2cw[\"sum\"].abs()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input consolidated vaultVault Timings - Unit Wise_05102023_101020.xls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ec1d1ab4da62>:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vault_o_late[\"dayname\"] =vault_o_late[\"POST_DATE\"].dt.strftime('%A')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input consolidated cash in transit90113016 Cash in Transit PKR.xls\n",
      "WARNING *** file size (198642) not 512 + multiple of sector size (512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ec1d1ab4da62>:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ubil[\"vch_narration\"] =ubil[\"vch_narration\"].str.lower()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  Accounts KYC ReviewAccounts KYC Review_05102023_091036.xls\n",
      "Input Remittance RegisterRemittance Register_05102023_101011.xls\n",
      "Input account status reportAccount Status_05102023_091025.xls\n",
      "Input Remittance Register_11072023_110712.xlsRemittance Register_05102023_101011.xls\n",
      "Zakat Exemption AccountsZakat Exemption Accounts_05102023_091059.xls\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "DTR = input(\"Input consolidated DTR\")\n",
    "DTR = pd.read_excel(DTR)\n",
    "\n",
    "#-------- cash deposit display ------------------------------------------------------------------------------------------------------\n",
    "cash = DTR.copy()\n",
    "cash1 = cash[cash[\"txn_code\"] == 300]\n",
    "cash12 = cash[cash[\"txn_code\"] == 640]\n",
    "frames = [cash1, cash12]\n",
    "cash_late = pd.concat(frames)\n",
    "cash_late[\"tr_time\"]\n",
    "cash_late[\"tr_time\"] = cash_late[\"tr_time\"].astype('datetime64[ns]')\n",
    "\n",
    "cash_late['time']= cash_late[\"tr_time\"].dt.time\n",
    "time_Cash = cash_late.set_index('tr_time').between_time('18:30:00', '23:00:00')\n",
    "deposit_late = time_Cash[['unit_id', 'tnx_date', 'tnx_no', 'batch_no', 'acc_unit_id',\n",
    "       'account_no', 'account_title', 'post_date', 'value_date',\n",
    "       'release_date', 'txn_code', 'currency_code', 'amount', 'local_eqv',\n",
    "       'ex_rate', 'ex_rate_code', 'vch_narration', 'charge_code',\n",
    "       'trans_amt_type', 'drcr_flag', 'doc_id', 'instrument_no', 'narrative',\n",
    "       'trans_type', 'product_code', 'emp_id', 'time']].reset_index()\n",
    "\n",
    "#---------------- withdraawl delay -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "cash = DTR.copy()\n",
    "w1 = cash[cash[\"txn_code\"] == 319]\n",
    "w2 = cash[cash[\"txn_code\"] == 651]\n",
    "frames_w = [w1, w2]\n",
    "w_late = pd.concat(frames_w)\n",
    "w_late[\"tr_time\"]\n",
    "w_late[\"tr_time\"] = w_late[\"tr_time\"].astype('datetime64[ns]')\n",
    "\n",
    "w_late['time']= w_late[\"tr_time\"].dt.time\n",
    "time_Cash_w = w_late.set_index('tr_time').between_time('18:30:00', '23:00:00')\n",
    "w_late = time_Cash_w[['unit_id', 'tnx_date', 'tnx_no', 'batch_no', 'acc_unit_id',\n",
    "       'account_no', 'account_title', 'post_date', 'value_date',\n",
    "       'release_date', 'txn_code', 'currency_code', 'amount', 'local_eqv',\n",
    "       'ex_rate', 'ex_rate_code', 'vch_narration', 'charge_code',\n",
    "       'trans_amt_type', 'drcr_flag', 'doc_id', 'instrument_no', 'narrative',\n",
    "       'trans_type', 'product_code', 'emp_id', 'time']].reset_index()\n",
    "\n",
    "#--------- Inward Clearing --------------------------------------------------------------------------------------------------------\n",
    "inward = DTR.copy()\n",
    "inw = inward[inward[\"txn_code\"] == 349]\n",
    "\n",
    "inw[\"tr_time\"] =inw[\"tr_time\"].astype('datetime64[ns]')\n",
    "inw['time']= inw[\"tr_time\"].dt.time\n",
    "inw_c =inw.set_index('tr_time').between_time('13:30:00', '23:00:00')\n",
    "\n",
    "inw_c.reset_index(inplace= True)\n",
    "\n",
    "inward_clearing = inw_c[inw_c[\"trans_type\"]=='INCLR' ]\n",
    "\n",
    "#----------- STAN NO 641 -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "stan = DTR.copy()\n",
    "stan[\"account_no\"]=stan[\"account_no\"].astype(str)\n",
    "stan_gl= stan.query(\"account_no.str.len() == 8\", engine=\"python\")\n",
    "stangl_41 = stan_gl[stan_gl[\"txn_code\"] == 641]\n",
    "stan_no_641 = stangl_41.query(\"vch_narration.str.len() <= 10\", engine=\"python\")\n",
    "\n",
    "#-------- CD CTR without GL -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ctr = DTR.copy()\n",
    "ctr1 = ctr[ctr[\"txn_code\"] == 300]\n",
    "ctr2 = ctr[ctr[\"txn_code\"] == 640]\n",
    "framesctr = [ctr1, ctr2]\n",
    "ctr_con = pd.concat(framesctr)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "ctr_con[\"account_no\"]=ctr_con[\"account_no\"].astype(str)\n",
    "ctr_con= ctr_con.query(\"account_no.str.len() > 8\", engine=\"python\")\n",
    "#--------------------------------------------------------\n",
    "ctr_con[\"transaction_count\"] = ctr_con.groupby([\"account_no\", \"tnx_date\"])[\"account_no\"].transform(\"size\")\n",
    "#--------------------------------------------------------\n",
    "data2 = ctr_con[ctr_con[\"transaction_count\"] != 1]\n",
    "#--------------------------------------------------------\n",
    "data2[\"sum\"]= data2.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
    "#--------------------------------------------------------\n",
    "twomil = data2[data2[\"sum\"] >= 2000000 ]\n",
    "\n",
    "\n",
    "#---------------CD CTR WITH GL---------------------------------------------------------------------------------------------------------\n",
    "ctr = DTR.copy()\n",
    "ctr1 = ctr[ctr[\"txn_code\"] == 300]\n",
    "ctr2 = ctr[ctr[\"txn_code\"] == 640]\n",
    "framesctr = [ctr1, ctr2]\n",
    "ctr_con = pd.concat(framesctr)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "ctr_con[\"account_no\"]=ctr_con[\"account_no\"].astype(str)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "ctr_con[\"transaction_count\"] = ctr_con.groupby([\"account_no\", \"tnx_date\"])[\"account_no\"].transform(\"size\")\n",
    "#--------------------------------------------------------\n",
    "data2 = ctr_con[ctr_con[\"transaction_count\"] != 1]\n",
    "#--------------------------------------------------------\n",
    "data2[\"sum\"]= data2.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
    "#--------------------------------------------------------\n",
    "data2[\"sum\"] =data2[\"sum\"].abs()\n",
    "#--------------------------------------------------------\n",
    "twomilgl = data2[data2[\"sum\"] >= 2000000 ]\n",
    "twomilgl.shape\n",
    "\n",
    "#----------------- CW CTR WITHOUT GL ----------------------------------------------------------------------------------------------------------------\n",
    "ctrcw = DTR.copy()\n",
    "ctr1cw = ctrcw[ctrcw[\"txn_code\"] == 319]\n",
    "ctr2cw = ctrcw[ctrcw[\"txn_code\"] == 651]\n",
    "framesctr = [ctr1cw, ctr2cw]\n",
    "ctr_concw = pd.concat(framesctr)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "ctr_concw[\"account_no\"]=ctr_concw[\"account_no\"].astype(str)\n",
    "ctr_concw= ctr_concw.query(\"account_no.str.len() > 8\", engine=\"python\")\n",
    "#--------------------------------------------------------\n",
    "ctr_concw.groupby([\"account_no\", \"tnx_date\"])[\"account_no\"].transform(\"size\")\n",
    "\n",
    "ctr_concw[\"transaction_count\"] = ctr_concw.groupby([\"account_no\", \"tnx_date\"])[\"account_no\"].transform(\"size\")\n",
    "\n",
    "data2cw = ctr_concw[ctr_concw[\"transaction_count\"] != 1]\n",
    "\n",
    "data2cw.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
    "\n",
    "data2cw[\"sum\"]= data2cw.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
    "data2cw[\"sum\"] =data2cw[\"sum\"].abs()\n",
    "#--------------------------------------------------------\n",
    "twomilcw = data2cw[data2cw[\"sum\"] >= 2000000 ]\n",
    "twomilcw.shape\n",
    "\n",
    "#----------------- CW CTR WITH GL ----------------------------------------------------------------------------------------------------------------\n",
    "ctrcw = DTR.copy()\n",
    "ctr1cw = ctrcw[ctrcw[\"txn_code\"] == 319]\n",
    "ctr2cw = ctrcw[ctrcw[\"txn_code\"] == 651]\n",
    "framesctr = [ctr1cw, ctr2cw]\n",
    "ctr_concw = pd.concat(framesctr)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "ctr_concw[\"account_no\"]=ctr_concw[\"account_no\"].astype(str)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "ctr_concw.groupby([\"account_no\", \"tnx_date\"])[\"account_no\"].transform(\"size\")\n",
    "\n",
    "ctr_concw[\"transaction_count\"] = ctr_concw.groupby([\"account_no\", \"tnx_date\"])[\"account_no\"].transform(\"size\")\n",
    "\n",
    "data2cw = ctr_concw[ctr_concw[\"transaction_count\"] != 1]\n",
    "\n",
    "data2cw.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
    "\n",
    "data2cw[\"sum\"]= data2cw.groupby([\"account_no\", \"tnx_date\"])[\"local_eqv\"].transform(sum)\n",
    "data2cw[\"sum\"] =data2cw[\"sum\"].abs()\n",
    "#--------------------------------------------------------\n",
    "twomilcwgl = data2cw[data2cw[\"sum\"] >= 2000000 ]\n",
    "\n",
    "#----------- vault late FILE UPLOAD -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "vault = input(\"Input consolidated vault\")\n",
    "vault = pd.read_excel(vault)\n",
    "\n",
    "\n",
    "vault_o = vault[['UNIT_ID', 'UNIT_NAME', 'POST_DATE', 'VAULT_OPEN_TIME']]\n",
    "vault_p = vault[['UNIT_ID', 'UNIT_NAME', 'POST_DATE', 'VAULT_CLOSE_TIME']]\n",
    "\n",
    "\n",
    "#----------- vault late close-----------------------------------------------------------------------------------------------------------------\n",
    "vault_p_late = vault_p[vault_p[\"VAULT_CLOSE_TIME\"] > \"19:30:00\" ]\n",
    "\n",
    "\n",
    "vault_p_late[\"dayname\"] =vault_p_late[\"POST_DATE\"].dt.strftime('%A')\n",
    "vault_p_late = vault_p_late[vault_p_late[\"dayname\"] != 'Saturday']\n",
    "\n",
    "\n",
    "\n",
    "#----------- vault late open-----------------------------------------------------------------------------------------------------------------\n",
    "vault_o_late = vault_o[vault_o[\"VAULT_OPEN_TIME\"] > \"09:03:00\" ]\n",
    "vault_o_late[\"dayname\"] =vault_o_late[\"POST_DATE\"].dt.strftime('%A')\n",
    "vault_o_late = vault_o_late[vault_o_late[\"dayname\"] != 'Saturday']\n",
    "\n",
    "#------------- cash in transit -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "cit = input(\"Input consolidated cash in transit\")\n",
    "cit = pd.read_excel(cit)\n",
    "\n",
    "\n",
    "cit = cit.iloc[13:]\n",
    "cit .columns = cit .iloc[0]\n",
    "\n",
    "# Drop the first row\n",
    "cit  = cit[1:]\n",
    "cit[\"Balance\"] =cit[\"Balance\"].fillna(0)\n",
    "cit = cit[cit[\"Balance\"] != 0]\n",
    "\n",
    "#--------- late utility bill-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ubill = DTR.copy()\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "values_to_removes = [\"fed\", \"FED\", \"Fed\"]\n",
    "\n",
    "# Remove the rows where the column value is in the list of values to remove\n",
    "column_names = \"vch_narration\"\n",
    "\n",
    "def contains_fed(value):\n",
    "    for word in values_to_removes:\n",
    "        if word in value:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#df = df[~df[column_name].apply(contains_fed)]\n",
    "ubil = ubill[~ubill[column_names].apply(contains_fed)]\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "ubil[\"vch_narration\"] =ubil[\"vch_narration\"].str.lower()\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "column_names = \"vch_narration\"\n",
    "values_to_removess = [\"bil\", \"bills\", \"bill\",\"bils\"]\n",
    "def contains_fed(value):\n",
    "    for word in values_to_removess:\n",
    "        if word in value:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#df = df[~df[column_name].apply(contains_fed)]\n",
    "utility_late = ubil[ubil[column_names].apply(contains_fed)]\n",
    "utility_late = utility_late[utility_late[\"tr_time\"] > \"19:00:00\" ]\n",
    "#-------------- KYC IMPORT --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "KYC = input(\"Input  Accounts KYC Review\")\n",
    "KYC = pd.read_excel(KYC)\n",
    "\n",
    "\n",
    "\n",
    "#KYC_NORMAL\n",
    "KYC[\"Account_Status\"] = KYC[\"Account_Status\"].str.upper()\n",
    "KYC[\"Risk_level\"] = KYC[\"Risk_level\"].str.lower()\n",
    "KYC_NORMAL = KYC[KYC[\"Account_Status\"] == \"NORMAL\"]\n",
    "\n",
    "#*-------- ACCOUNT KYC REVIEW BLANK RISK -----------------------------------------------------------------------------------------------------------------\n",
    "blank = KYC_NORMAL.copy()\n",
    "bol = blank[\"Risk_level\"].isnull()\n",
    "blank = blank[bol]\n",
    "\n",
    "\n",
    "#-------- ACCOUNT KYC REVIEW *high** RISK -----------------------------------------------------------------------------------------------------------------\n",
    "high = KYC_NORMAL.copy()\n",
    "\n",
    "high = high[high[\"Risk_level\"] == \"high\"]\n",
    "\n",
    "current_date = pd.to_datetime(\"2023-10-01\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "high[\"datediff\"] = high[\"Revise_Date\"]- current_date\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "high_final =high[high[\"datediff\"].dt.days < -365]\n",
    "\n",
    "#-------- ACCOUNT KYC REVIEW *medium** RISK ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "medium = KYC_NORMAL.copy()\n",
    "#-----------\n",
    "medium = medium[medium[\"Risk_level\"] == \"medium\"]\n",
    "\n",
    "current_date = pd.to_datetime(\"2023-07-01\")\n",
    "#-------------------------------------------------------\n",
    "medium[\"datediff\"] = medium[\"Revise_Date\"]- current_date\n",
    "\n",
    "#-------------------------------\n",
    "medium_final =medium[medium[\"datediff\"].dt.days < -730]\n",
    "\n",
    "\n",
    "#-------- ACCOUNT KYC REVIEW *low** RISK -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "low = KYC_NORMAL.copy()\n",
    "\n",
    "\n",
    "#-----------\n",
    "\n",
    "low = low[low[\"Risk_level\"] == \"low\"]\n",
    "\n",
    "current_date = pd.to_datetime(\"2023-07-01\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "low[\"datediff\"] = low[\"Revise_Date\"]- current_date\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "low_final =low[low[\"datediff\"].dt.days < -1461]\n",
    "\n",
    "\n",
    "\n",
    "#---------- donation to source income ------------------------------------------------------------------------------------------------------------\n",
    "dtn = KYC_NORMAL.copy()\n",
    "#-----------------------------------------------\n",
    "\n",
    "dtn[\"Donation\"] = dtn[\"Donation\"].str.upper()\n",
    "dtn[\"Source_of_Income\"] = dtn[\"Source_of_Income\"].str.upper()\n",
    "\n",
    "#----------------------------------------------------------\n",
    "donation_source = dtn[(dtn[\"Donation\"]==\"Y\") & (dtn[\"Source_of_Income\"] ==\"Y\")]\n",
    "\n",
    "#----------------------- PO WITHOUT INSTRUMENT --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "pwi = input(\"Input Remittance Register\")\n",
    "pwi = pd.read_excel(pwi)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "pwi[\"Status\"] =pwi[\"Status\"].str.upper()\n",
    "#-------------------------------------------------------------\n",
    "pwi_c = pwi[pwi[\"Status\"] != \"C\"]\n",
    "pwi_c_icd = pwi_c[pwi_c['Instrument_Type'] != \"ICD\"]\n",
    "#-------------------------------------------------------------\n",
    "po_without = pwi_c_icd[pwi_c_icd[\"Cheque_No\"] == 0]\n",
    "\n",
    "\n",
    "#----------------------------------- UNCLAIMED ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "acc_st = input(\"Input account status report\")\n",
    "acc_st = pd.read_excel(acc_st)\n",
    "\n",
    "\n",
    "\n",
    "acc_st[\"ACCOUNT_STATUS\"] = acc_st[\"ACCOUNT_STATUS\"].str.upper()\n",
    "\n",
    "acc_st = acc_st[acc_st[\"ACCOUNT_STATUS\"] == \"DORMANT\"]\n",
    "\n",
    "current_date_a = pd.to_datetime(\"2023-06-30\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "acc_st[\"datediff\"] = acc_st[\"STATUS_DATE\"]- current_date_a\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "unclaimed =acc_st[acc_st[\"datediff\"].dt.days < -3650]\n",
    "\n",
    "\n",
    "#----------------- PO ABREVIATED ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "po_ab = input(\"Input Remittance Register_11072023_110712.xls\")\n",
    "po_ab = pd.read_excel(po_ab)\n",
    "\n",
    "\n",
    "\n",
    "po_ab[\"Status\"] =po_ab[\"Status\"].str.upper()\n",
    "#-------------------------------------------------------------\n",
    "po_ab = po_ab[po_ab[\"Status\"] != \"C\"]\n",
    "po_ab = po_ab[po_ab['Instrument_Type'] != \"ICD\"]\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "def is_abbreviated(name):\n",
    "    for i in range(len(name)):\n",
    "        if not name[i].isalpha() and name[i] != '.':\n",
    "            return True\n",
    "    return False\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "po_abreviated = po_ab[po_ab[\"Unit_Name\"].apply(is_abbreviated)]\n",
    "\n",
    "\n",
    "#------------------------ Zakat exemption ------------------------------------------------------------------------------------------------------------------------\n",
    "ze = input(\"Zakat Exemption Accounts\")\n",
    "ze = pd.read_excel(ze)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "column_name = \"Account_Title\"\n",
    "\n",
    "# Get the list of values to remove\n",
    "values_to_remove = [\"Enterprise\", \"enterprises\", \"ltd\",\"Limited\",\"limited\",\"CO\",\"corperate\",\"Lancer\",\"Motors\",\"motor\",\"MOTORS\"\n",
    "                   , \"Goverment\", \"goverment\",\"Division\",\"Divisions\",\"divisions\",\"Soft\",\"International\",\"estate\",\"Real\",\"real\",\n",
    "                   \"Real estate\",\"contractor\",\"Contractor\",\"Plaza\",\"govt\", \"COMPANY\",\"trader\"]\n",
    "\n",
    "def contains_fed(value):\n",
    "    for word in values_to_remove:\n",
    "        if word in value.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#df = df[~df[column_name].apply(contains_fed)]\n",
    "zakat_exemp = ze[ze[column_name].apply(contains_fed)]\n",
    "\n",
    "\n",
    "## Create an Excel writer object--------------------------------------------------------------------------------------------\n",
    "excel_file = \"Annexure.xlsx\"\n",
    "writer = pd.ExcelWriter(excel_file, engine='xlsxwriter')\n",
    "\n",
    "# Dictionary containing DataFrames and corresponding sheet names\n",
    "dataframes = {\n",
    "    'Unclaimed': unclaimed,\n",
    "    'PO without instrument': po_without,\n",
    "    'Donation to Source income': donation_source,\n",
    "    'Low risk': low_final, \n",
    "    'Medium risk': medium_final, \n",
    "    'High risk': high_final, \n",
    "    'Blank risk': blank,\n",
    "    'Utility bill': utility_late,\n",
    "    'Cash in transit': cit,\n",
    "    'Vault Open late': vault_o_late,\n",
    "    'Vault Late close': vault_p_late,\n",
    "    'CW CTR': twomilcw,\n",
    "    'CD CTR': twomil,\n",
    "    'STAN no 641': stan_no_641,\n",
    "    'Inward clearing': inward_clearing,\n",
    "    'Withdrawl late': w_late,\n",
    "    'Deposit late': deposit_late,\n",
    "    #'PO Abreviated': po_abreviated,\n",
    "    'Zakat exemption': zakat_exemp\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add more sheets and corresponding DataFrames as needed\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and write each DataFrame to a separate sheet\n",
    "for sheet_name, dataframe in dataframes.items():\n",
    "    dataframe.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a288e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2745f4",
   "metadata": {},
   "source": [
    "vault_o_late[\"dayname\"] =vault_o_late[\"POST_DATE\"].dt.strftime('%A')\n",
    "valts = vault_o_late[vault_o_late[\"dayname\"] != 'Saturday']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17464f8",
   "metadata": {},
   "source": [
    "vault_o_late[\"dayname\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6029bd",
   "metadata": {},
   "source": [
    "valts = vault_o_late[vault_o_late[\"dayname\"] != 'Saturday']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23aded",
   "metadata": {},
   "source": [
    "valts.to_excel(\"vault_sat.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5f9e4",
   "metadata": {},
   "source": [
    "vault_o_late[\"POST_DATE\"].day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6c1e7",
   "metadata": {},
   "source": [
    "vault_o_late[\"POST_DATE\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79802d",
   "metadata": {},
   "source": [
    "vault_o_late[\"POST_DATE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d49da",
   "metadata": {},
   "source": [
    "vault_o_late[vault_o_late[\"dayname\"] != 'Saturday']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556c3aa",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "vault = pd.read_excel(\"Vault Timings - Unit Wise_04102023_121042.xls\")\n",
    "\n",
    "\n",
    "vault_o = vault[['UNIT_ID', 'UNIT_NAME', 'POST_DATE', 'VAULT_OPEN_TIME']]\n",
    "\n",
    "#----------- vault late open-----------------------------------------------------------------------------------------------------------------\n",
    "vault_o_late = vault_o[vault_o[\"VAULT_OPEN_TIME\"] > \"09:03:00\" ]\n",
    "vault_o_late[\"dayname\"] =vault_o_late[\"POST_DATE\"].dt.strftime('%A')\n",
    "vault_o_late = vault_o_late[vault_o_late[\"dayname\"] != 'Saturday']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbeb2e",
   "metadata": {},
   "source": [
    "vault_o_late "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed105a5",
   "metadata": {},
   "source": [
    "vault_o_late.to_excel(\"openlate.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c128892",
   "metadata": {},
   "source": [
    "#----------- vault late close-----------------------------------------------------------------------------------------------------------------\n",
    "vault_p_late = vault_p[vault_p[\"VAULT_CLOSE_TIME\"] > \"19:30:00\" ]\n",
    "\n",
    "vault_p_late[\"dayname\"] =vault_p_late[\"POST_DATE\"].dt.strftime('%A')\n",
    "vault_p_late = vault_p_late[vault_p_late[\"dayname\"] != 'Saturday']\n",
    "vault_p_late"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a470174",
   "metadata": {},
   "source": [
    "vault_p_late.to_csv(\"late vault.csv \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb296d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
